[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We are from Beijing Normal University. We have developed more than 50 tasks based on psychological paradigms, in order to explore the structure of human cognition."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cognitive Structure Project",
    "section": "",
    "text": "structure\n\n\ncognition\n\n\nmeta-analysis\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2022\n\n\nYifei Cao, Liang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstructure\n\n\nwm\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2022\n\n\nLiang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata-check\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2022\n\n\nLiang Zhang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/check-raw-data/index.html",
    "href": "posts/check-raw-data/index.html",
    "title": "Check Raw Data",
    "section": "",
    "text": "Here we check raw data from several special tasks. Especially check the factors influencing reliability, internal consistency of each task"
  },
  {
    "objectID": "posts/check-raw-data/index.html#schulte-grid-舒尔特方格",
    "href": "posts/check-raw-data/index.html#schulte-grid-舒尔特方格",
    "title": "Check Raw Data",
    "section": "Schulte Grid (舒尔特方格)",
    "text": "Schulte Grid (舒尔特方格)\n\n\nCode\ntargets::tar_load(data_valid_SchulteMed, store = here::here(\"preproc/_targets\"))\nrt_by_resp <- data_valid_SchulteMed |>\n  mutate(\n    raw_parsed = map(\n      raw_parsed,\n      ~ . |> mutate(resp = as.integer(resp))\n    )\n  ) |>\n  unnest(raw_parsed) |>\n  group_by(user_id, game_time) |>\n  mutate(resp_adj = ifelse(acc == 0, NA, resp)) |>\n  fill(resp_adj, .direction = \"up\") |>\n  ungroup() |>\n  drop_na() |>\n  group_by(user_id, game_version, game_time, resp_adj) |>\n  summarise(rt = sum(rt) / 1000, .groups = \"drop\") |>\n  filter(rt < 300)\nrt_by_resp |>\n  ggplot(aes(resp_adj, rt, color = game_version)) +\n  geom_point(shape = \".\") +\n  geom_smooth() +\n  scale_y_log10() +\n  scale_color_brewer(palette = \"Paired\") +\n  labs(x = \"\", y = \"Response Time (s)\", color = \"Version\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html",
    "href": "posts/explore-struct-wm/index.html",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(corrr)\nlibrary(BayesFM)\nThe include tasks:"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#traditional",
    "href": "posts/explore-struct-wm/index.html#traditional",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Traditional",
    "text": "Traditional\n\n\nCode\nnfactors_test <- psych::nfactors(indices_memory)\n\n\n\n\n\n\nCorrelated latent factors\n\n\n\nCode\nfit <- psych::fa(indices_memory, 3)\npsych::fa.diagram(fit)\n\n\n\n\n\n\nBifactor model\n\n\n\nCode\nfit_bifac <- psych::omega(indices_memory, 3, plot = FALSE)\npsych::omega.diagram(fit_bifac)"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#bayesian-factor-analysis",
    "href": "posts/explore-struct-wm/index.html#bayesian-factor-analysis",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Bayesian Factor Analysis",
    "text": "Bayesian Factor Analysis\n\n\nCode\nmcmc <- indices_memory |> \n  mutate(across(.fns = ~ scale(.)[, 1])) |> \n  befa(verbose = FALSE) |> \n  post.column.switch() |> \n  post.sign.switch()\n\n\n\n\nCode\nhppm <- summary(mcmc, what = \"hppm\")\nhppm |> \n  pluck(\"alpha\", \"m1\") |> \n  as_tibble(rownames = \"alpha_term\") |> \n  separate(alpha_term, c(NA, \"game_index\"), sep = \":\") |> \n  mutate(game_index = reorder(game_index, dedic)) |> \n  ggplot(aes(game_index, dedic)) +\n  geom_tile(aes(fill = mean)) +\n  geom_text(aes(label = round(mean, 2)), color = \"white\") +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"Term\", y = \"Factor\", \n       title = str_c(\"Posterior Probability: \", round(hppm$hppm$prob, 2), \n                     \", with \", hppm$hppm$nfac, \" factors\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/Large-scale meta analysis/index.html",
    "href": "posts/Large-scale meta analysis/index.html",
    "title": "Extracting Cognitive Factors from Large-Scale Meta-Anslysis Data",
    "section": "",
    "text": "To summarize briefly, I followed the step of Beam et al. (2021, Nature Neuroscience) to find evidence for the structure of human cognition. Firstly, filtering all studies that included the testing paradigms that consisted with those used in our project from the database of Neurosynth, I conducted 28 meta-analysis separately on each group of fMRI studies. Thanks to NiMARE (a python research environment for neuroimaging meta-analysis), I could easily perform Multilevel Kernel Density Analysis (MKDA) on hundreds fMRI studies without manually coding.\nHere is the summarize table for the number of included fMRI studies in each meta-analysis."
  },
  {
    "objectID": "posts/Large-scale meta analysis/index.html#traditional",
    "href": "posts/Large-scale meta analysis/index.html#traditional",
    "title": "Extracting Cognitive Factors from Large-Scale Meta-Anslysis Data",
    "section": "Traditional",
    "text": "Traditional\n\n\nCode\nnfactors_test <- psych::nfactors(cor_nonzero)\n\n\n\n\n\n\nCorrelated latent factors\n\n\n\nCode\nfit <- psych::fa(cor_nonzero, 4)\npsych::fa.diagram(fit)\n\n\n\n\n\n\nBifactor model\n\n\n\nCode\nfit_bifac <- psych::omega(total_nonzero, 3, plot = FALSE)\npsych::omega.diagram(fit_bifac)"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#model-from-efa",
    "href": "posts/explore-struct-wm/index.html#model-from-efa",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Model from EFA",
    "text": "Model from EFA\nFirstly, the model from EFA is tested.\n\nSpatial-object association test (宇宙黑洞) included\n\n\n\nCode\nfitted1 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_memory, std.lv = TRUE, std.ov = TRUE\n)\nsemPlot::semPaths(\n  fitted1, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 17 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           314         468\n                                                                  \nModel Test User Model:\n                                                      \n  Test statistic                               104.853\n  Degrees of freedom                                41\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               809.797\n  Degrees of freedom                                55\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.915\n  Tucker-Lewis Index (TLI)                       0.887\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4543.033\n  Loglikelihood unrestricted model (H1)      -4490.606\n                                                      \n  Akaike (AIC)                                9136.065\n  Bayesian (BIC)                              9229.800\n  Sample-size adjusted Bayesian (BIC)         9150.508\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.070\n  90 Percent confidence interval - lower         0.054\n  90 Percent confidence interval - upper         0.087\n  P-value RMSEA <= 0.05                          0.022\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.051\n\n\n\nSpatial-object association test (宇宙黑洞) excluded\n\n\n\nCode\nfitted2 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_memory, std.lv = TRUE, std.ov = TRUE\n)\nsemPlot::semPaths(\n  fitted2, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 17 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                                      \n  Test statistic                                80.279\n  Degrees of freedom                                32\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               752.317\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.932\n  Tucker-Lewis Index (TLI)                       0.904\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4227.955\n  Loglikelihood unrestricted model (H1)      -4187.816\n                                                      \n  Akaike (AIC)                                8501.910\n  Bayesian (BIC)                              8588.725\n  Sample-size adjusted Bayesian (BIC)         8515.772\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.068\n  90 Percent confidence interval - lower         0.050\n  90 Percent confidence interval - upper         0.087\n  P-value RMSEA <= 0.05                          0.051\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.047"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#task-structure-model",
    "href": "posts/explore-struct-wm/index.html#task-structure-model",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Task Structure Model",
    "text": "Task Structure Model\n\nThe covariance estimate for latent variables is not correct. The estimated correlation between “Simple” and “Complex” is 1.02.\n\n\n\nCode\nfitted3 <- lavaan::cfa(\n  'Complex =~ `打靶场` + `蝴蝶照相机` + `幸运小球`\n  Nback =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  Simple =~ `密码箱` + `顺背数PRO` + `位置记忆PRO`',\n  indices_memory, std.lv = TRUE, std.ov = TRUE\n)\nsemPlot::semPaths(\n  fitted3, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted3, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 19 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                                      \n  Test statistic                               163.052\n  Degrees of freedom                                32\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               752.317\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.815\n  Tucker-Lewis Index (TLI)                       0.739\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4269.341\n  Loglikelihood unrestricted model (H1)      -4187.816\n                                                      \n  Akaike (AIC)                                8584.683\n  Bayesian (BIC)                              8671.498\n  Sample-size adjusted Bayesian (BIC)         8598.545\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.113\n  90 Percent confidence interval - lower         0.096\n  90 Percent confidence interval - upper         0.130\n  P-value RMSEA <= 0.05                          0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.076"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#input-material-model",
    "href": "posts/explore-struct-wm/index.html#input-material-model",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Input Material Model",
    "text": "Input Material Model\n\nNot fitted well.\n\n\n\nCode\nfitted4 <- lavaan::cfa(\n  'Verbal =~ 数字卡片 + 文字卡片 + 幸运小球 + 密码箱 + 顺背数PRO\n  Spatial =~ 格子卡片 + 打靶场 + 蝴蝶照相机 + 位置记忆PRO\n  Object =~ 美术卡片 + 宇宙黑洞',\n  indices_memory, std.lv = TRUE, std.ov = TRUE\n)\nsemPlot::semPaths(\n  fitted4, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted4, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 21 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           314         468\n                                                                  \nModel Test User Model:\n                                                      \n  Test statistic                               265.138\n  Degrees of freedom                                41\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               809.797\n  Degrees of freedom                                55\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.703\n  Tucker-Lewis Index (TLI)                       0.602\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4623.176\n  Loglikelihood unrestricted model (H1)      -4490.606\n                                                      \n  Akaike (AIC)                                9296.351\n  Bayesian (BIC)                              9390.086\n  Sample-size adjusted Bayesian (BIC)         9310.793\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.132\n  90 Percent confidence interval - lower         0.117\n  90 Percent confidence interval - upper         0.147\n  P-value RMSEA <= 0.05                          0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.098"
  },
  {
    "objectID": "posts/check-raw-data/index.html#reasoning-推理类题目",
    "href": "posts/check-raw-data/index.html#reasoning-推理类题目",
    "title": "Check Raw Data",
    "section": "Reasoning (推理类题目)",
    "text": "Reasoning (推理类题目)\n\n\nCode\ntargets::tar_load(data_valid_DRA, store = here::here(\"preproc/_targets\"))\ndata_valid_DRA |>\n  filter(course_name == \"清华大学认知实验D\") |>\n  unnest(raw_parsed) |>\n  mutate(item = as.numeric(as_factor(itemid))) |>\n  # group_by(item) |>\n  # filter(between(mean(acc == 1), 0.6, 0.9)) |>\n  # ungroup() |>\n  filter(acc != -1) |>\n  pivot_wider(\n    id_cols = user_id,\n    names_from = item,\n    values_from = acc\n  ) |>\n  select(-user_id)"
  },
  {
    "objectID": "posts/check-raw-data/index.html#forward-word-span-过目不忘",
    "href": "posts/check-raw-data/index.html#forward-word-span-过目不忘",
    "title": "Check Raw Data",
    "section": "Forward Word Span (过目不忘)",
    "text": "Forward Word Span (过目不忘)\n\n\nCode\ntargets::tar_load(data_valid_FWSPro, store = here::here(\"preproc/_targets\"))\nchrs_freq <- read_tsv(\"CharFreq.txt\", skip = 5)\nchrs_used <- readxl::read_excel(\"过目不忘-汉字库.xlsx\") |>\n  left_join(chrs_freq, by = \"汉字\")\ndata_adj_acc <- data_valid_FWSPro |>\n  unnest(raw_parsed) |>\n  group_by(user_id, game_time) |>\n  mutate(trial = row_number()) |>\n  ungroup() |>\n  mutate(\n    across(\n      c(stim, resp),\n      str_split,\n      pattern = \"-\"\n    )\n  ) |>\n  unnest(c(stim, resp)) |>\n  left_join(\n    select(chrs_used, stim = 汉字, stim_id = ID, stim_freq = 序列号),\n    by = \"stim\"\n  ) |>\n  left_join(\n    select(chrs_used, resp = 汉字, resp_id = ID),\n    by = \"resp\"\n  ) |>\n  separate(stim_id, c(\"stim_phon\", \"stim_form\"), convert = TRUE) |>\n  separate(resp_id, c(\"resp_phon\", \"resp_form\"), convert = TRUE) |>\n  mutate(\n    acc = case_when(\n      stim == resp ~ \"正确\",\n      stim_phon == resp_phon ~ \"同音字\",\n      stim_phon != resp_phon ~ \"错误\"\n    )\n  )\ndata_adj_acc |>\n  group_by(stim, stim_phon, stim_freq, acc) |>\n  summarise(n = n(), .groups = \"drop_last\") |>\n  mutate(prop = n / sum(n)) |>\n  ungroup() |>\n  ggplot(aes(stim, prop, fill = acc)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(\n    aes(label = scales::label_percent(accuracy = 1)(prop)),\n    position = position_stack(vjust = 0.5),\n    color = \"white\"\n  ) +\n  geom_text(\n    aes(label = stim_freq),\n    y = 0\n  ) +\n  scale_fill_brewer(palette = \"Accent\") +\n  facet_wrap(~ stim_phon, scales = \"free_x\", nrow = 1) +\n  labs(x = \"\", y = \"\", fill = \"\") +\n  # scale_y_continuous(expand = c(0, 0)) +\n  ggthemes::theme_hc() +\n  theme(\n    axis.text.x = element_text(family = \"SimHei\"),\n    legend.text = element_text(family = \"SimHei\")\n  )\n\n\n\n\n\nHomophone Selection Proportion"
  },
  {
    "objectID": "posts/check-raw-data/index.html#neuroracer-小狗回家",
    "href": "posts/check-raw-data/index.html#neuroracer-小狗回家",
    "title": "Check Raw Data",
    "section": "NeuroRacer (小狗回家)",
    "text": "NeuroRacer (小狗回家)\n\n\nCode\ndata_racer_new <- targets::tar_read(\n  data_valid_Racer, \n  store = here::here(\"preproc/_targets\")\n) |> \n  tidyr::unnest(raw_parsed) |> \n  dplyr::mutate(block = paste0(\"V\", block)) |> \n  dplyr::filter(block != \"V0\")\ndata_racer_new |> \n  dplyr::group_by(user_id, block) |> \n  dplyr::summarise(\n    mean_score = sum(escortscore * trialdur) / sum(trialdur),\n    .groups = \"drop\"\n  ) |> \n  tidyr::pivot_wider(\n    id_cols = user_id, \n    names_from = block, \n    values_from = mean_score\n  ) |> \n  dplyr::select(-user_id) |> \n  psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = dplyr::select(tidyr::pivot_wider(dplyr::summarise(dplyr::group_by(data_racer_new, \n    user_id, block), mean_score = sum(escortscore * trialdur)/sum(trialdur), \n    .groups = \"drop\"), id_cols = user_id, names_from = block, \n    values_from = mean_score), -user_id))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean    sd median_r\n      0.85      0.85     0.8      0.66 5.7 0.045 0.84 0.043     0.62\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.73  0.85  0.92\nDuhachek  0.76  0.85  0.94\n\n Reliability if an item is dropped:\n   raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nV2      0.75      0.76    0.61      0.61 3.2    0.084    NA  0.61\nV3      0.77      0.77    0.62      0.62 3.3    0.081    NA  0.62\nV1      0.84      0.85    0.73      0.73 5.5    0.054    NA  0.73\n\n Item statistics \n    n raw.r std.r r.cor r.drop mean    sd\nV2 33  0.91  0.89  0.83   0.76 0.84 0.045\nV3 33  0.90  0.89  0.82   0.75 0.85 0.055\nV1 30  0.83  0.85  0.71   0.66 0.83 0.045\n\n\nCode\ndata_racer_new |> \n  dplyr::group_by(user_id, block) |> \n  dplyr::group_modify(\n    ~ preproc.iquizoo::cpt(.x)\n  )|> \n  dplyr::ungroup() |> \n  tidyr::pivot_wider(\n    id_cols = user_id, \n    names_from = block, \n    values_from = dprime\n  ) |> \n  dplyr::select(-user_id) |> \n  psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = dplyr::select(tidyr::pivot_wider(dplyr::ungroup(dplyr::group_modify(dplyr::group_by(data_racer_new, \n    user_id, block), ~preproc.iquizoo::cpt(.x))), id_cols = user_id, \n    names_from = block, values_from = dprime), -user_id))\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean   sd median_r\n      0.52      0.53    0.45      0.27 1.1 0.15  2.3 0.55     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.14  0.52  0.75\nDuhachek  0.23  0.52  0.81\n\n Reliability if an item is dropped:\n   raw_alpha std.alpha G6(smc) average_r  S/N alpha se var.r med.r\nV2      0.37      0.38    0.23      0.23 0.60     0.22    NA  0.23\nV3      0.27      0.27    0.15      0.15 0.36     0.25    NA  0.15\nV1      0.59      0.60    0.42      0.42 1.48     0.14    NA  0.42\n\n Item statistics \n    n raw.r std.r r.cor r.drop mean   sd\nV2 33  0.77  0.73  0.53   0.36  2.4 0.82\nV3 33  0.75  0.77  0.60   0.44  2.3 0.69\nV1 30  0.64  0.64  0.31   0.22  2.1 0.78\n\n\n\n\nCode\ndata_racer_old <- targets::tar_read(\n  data_parsed_Racer, \n  store = here::here(\"preproc/_targets\")\n) |> \n  dplyr::filter(game_version == \"1.0.0\") |> \n  tidyr::unnest(raw_parsed) |> \n  dplyr::mutate(block = paste0(\"V\", block))\ndata_racer_old |> \n  dplyr::group_by(user_id, block) |> \n  dplyr::summarise(\n    mean_score = sum(produr * trialdur) / sum(trialdur),\n    .groups = \"drop\"\n  ) |> \n  tidyr::pivot_wider(\n    id_cols = user_id, \n    names_from = block, \n    values_from = mean_score\n  ) |> \n  dplyr::select(-user_id) |> \n  psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = dplyr::select(tidyr::pivot_wider(dplyr::summarise(dplyr::group_by(data_racer_old, \n    user_id, block), mean_score = sum(produr * trialdur)/sum(trialdur), \n    .groups = \"drop\"), id_cols = user_id, names_from = block, \n    values_from = mean_score), -user_id))\n\n  raw_alpha std.alpha G6(smc) average_r  S/N   ase mean sd median_r\n     0.098      0.13    0.11     0.028 0.14 0.073  221 80    0.018\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt    -0.06   0.1  0.24\nDuhachek -0.05   0.1  0.24\n\n Reliability if an item is dropped:\n   raw_alpha std.alpha G6(smc) average_r   S/N alpha se   var.r    med.r\nV1     0.162     0.161   0.130     0.046 0.192    0.072 0.00177  0.03686\nV2     0.075     0.099   0.079     0.027 0.110    0.077 0.00132  0.01817\nV3     0.079     0.106   0.085     0.029 0.118    0.076 0.00137  0.01817\nV4     0.028     0.039   0.031     0.010 0.041    0.079 0.00055  0.00446\nV5     0.073     0.104   0.087     0.028 0.116    0.076 0.00278 -0.00002\n\n Item statistics \n     n raw.r std.r  r.cor r.drop mean  sd\nV1 363  0.62  0.43 0.0067 0.0036  310 246\nV2 363  0.38  0.47 0.1675 0.0486  197 132\nV3 363  0.39  0.47 0.1501 0.0430  192 141\nV4 363  0.47  0.52 0.3053 0.0882  200 158\nV5 363  0.43  0.47 0.1460 0.0482  205 155\n\n\nCode\ndata_racer_old |> \n  dplyr::group_by(user_id, block) |> \n  dplyr::group_modify(\n    ~ preproc.iquizoo::cpt(.x)\n  )|> \n  dplyr::ungroup() |> \n  tidyr::pivot_wider(\n    id_cols = user_id, \n    names_from = block, \n    values_from = dprime\n  ) |> \n  dplyr::select(-user_id) |> \n  psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = dplyr::select(tidyr::pivot_wider(dplyr::ungroup(dplyr::group_modify(dplyr::group_by(data_racer_old, \n    user_id, block), ~preproc.iquizoo::cpt(.x))), id_cols = user_id, \n    names_from = block, values_from = dprime), -user_id))\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean  sd median_r\n      0.76      0.76    0.72      0.39 3.2 0.02  2.2 0.6     0.41\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.72  0.76   0.8\nDuhachek  0.72  0.76   0.8\n\n Reliability if an item is dropped:\n   raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nV1      0.73      0.73    0.67      0.40 2.7    0.023 0.0010  0.42\nV2      0.70      0.70    0.64      0.37 2.3    0.026 0.0037  0.38\nV3      0.71      0.71    0.66      0.38 2.4    0.025 0.0053  0.39\nV4      0.72      0.72    0.67      0.39 2.6    0.024 0.0036  0.41\nV5      0.72      0.72    0.67      0.39 2.6    0.024 0.0035  0.41\n\n Item statistics \n     n raw.r std.r r.cor r.drop mean   sd\nV1 363  0.70  0.69  0.57   0.49  1.6 0.88\nV2 363  0.76  0.75  0.66   0.58  2.2 0.91\nV3 363  0.73  0.73  0.63   0.55  2.4 0.83\nV4 363  0.69  0.70  0.59   0.51  2.4 0.80\nV5 363  0.68  0.70  0.59   0.51  2.5 0.76"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#correlation-matrix",
    "href": "posts/explore-struct-wm/index.html#correlation-matrix",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Correlation Matrix",
    "text": "Correlation Matrix\n\n\nCode\nindices_dft_set <- indices_memory |> \n  filter(index_name %in% c(\"mean_span_pcu\", \"dprime\")) |> \n  pivot_wider_indices() |>\n  select(-user_id)\ncorrelate(indices_dft_set, quiet = TRUE) |> \n  rearrange(method = \"HC\") |>\n  stretch() |> \n  mutate(across(c(x, y), as_factor)) |>\n  ggplot(aes(x, y)) +\n  geom_tile(aes(fill = r)) +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"\", y = \"\", fill = \"Pearson's\", color = \"\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#multidimensional-scaling",
    "href": "posts/explore-struct-wm/index.html#multidimensional-scaling",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Multidimensional Scaling",
    "text": "Multidimensional Scaling\n\n\nCode\nmds <- indices_dft_set |> \n  cor(use = \"pairwise\") |> \n  smacof::sim2diss(to.dist = TRUE) |> \n  smacof::mds(ndim = 2, type = \"mspline\")\n\n\nRegistered S3 methods overwritten by 'proxy':\n  method               from    \n  print.registry_field registry\n  print.registry_entry registry\n\n\nCode\n# plot(mds, plot.type = \"Shepard\", main = \"Shepard Diagram (Ratio Transformation)\")\n# par(family = \"SimHei\")\nplot(mds)"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#exploratory-factor-analysis",
    "href": "posts/explore-struct-wm/index.html#exploratory-factor-analysis",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Exploratory Factor Analysis",
    "text": "Exploratory Factor Analysis\n\nTraditional\n\n\nCode\nnfactors_test <- psych::nfactors(indices_dft_set)\n\n\n\n\n\n\nCorrelated latent factors\n\n\n\nCode\nfit <- psych::fa(indices_dft_set, 3)\n\n\nLoading required namespace: GPArotation\n\n\nCode\npsych::fa.diagram(fit)\n\n\n\n\n\n\nBifactor model\n\n\n\nCode\nfit_bifac <- psych::omega(indices_dft_set, 3, plot = FALSE)\npsych::omega.diagram(fit_bifac)\n\n\n\n\n\n\n\nBayesian Factor Analysis\n\n\nCode\nmcmc <- indices_dft_set |> \n  mutate(across(.fns = ~ scale(.)[, 1])) |> \n  befa(verbose = FALSE) |> \n  post.column.switch() |> \n  post.sign.switch()\n\n\n\n\nCode\nhppm <- summary(mcmc, what = \"hppm\")\nhppm |> \n  pluck(\"alpha\", \"m1\") |> \n  as_tibble(rownames = \"alpha_term\") |> \n  separate(alpha_term, c(NA, \"game_index\"), sep = \":\") |> \n  mutate(game_index = reorder(game_index, dedic)) |> \n  ggplot(aes(game_index, dedic)) +\n  geom_tile(aes(fill = mean)) +\n  geom_text(aes(label = round(mean, 2)), color = \"white\") +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"Term\", y = \"Factor\", \n       title = str_c(\"Posterior Probability: \", round(hppm$hppm$prob, 2), \n                     \", with \", hppm$hppm$nfac, \" factors\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#confirmatory-factor-analysis",
    "href": "posts/explore-struct-wm/index.html#confirmatory-factor-analysis",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Confirmatory Factor Analysis",
    "text": "Confirmatory Factor Analysis\n\nModel from EFA\nFirstly, the model from EFA is tested.\n\nSpatial-object association test (宇宙黑洞) included\n\nCorrelated latent factor model:\n\n\n\nCode\nfitted1 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_dft_set, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted1, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 24 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           314         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                43.640      86.790\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.360       0.000\n  Scaling correction factor                                  0.503\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1109.363    1109.363\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.957\n  Tucker-Lewis Index (TLI)                       0.997       0.942\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.978\n  Robust Tucker-Lewis Index (TLI)                            0.971\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.014       0.060\n  90 Percent confidence interval - lower         0.000       0.035\n  90 Percent confidence interval - upper         0.042       0.084\n  P-value RMSEA <= 0.05                          0.989       0.236\n                                                                  \n  Robust RMSEA                                               0.042\n  90 Percent confidence interval - lower                     0.030\n  90 Percent confidence interval - upper                     0.055\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.048       0.048\n\n\n\nBifactor model:\n\n\nNot converged.\n\n\n\nCode\nfitted1_bifac <- lavaan::cfa(\n  'Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_dft_set, std.lv = TRUE, std.ov = TRUE, orthogonal = TRUE, \n  estimator = \"WLSM\"\n)\n\n\nWarning in lavaan::lavaan(model = \"Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\", : lavaan WARNING:\n    the optimizer warns that a solution has NOT been found!\n\n\nCode\nsemPlot::semPaths(\n  fitted1_bifac, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,\n  bifactor = \"Common\"\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 24 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           314         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                43.640      86.790\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.360       0.000\n  Scaling correction factor                                  0.503\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1109.363    1109.363\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.957\n  Tucker-Lewis Index (TLI)                       0.997       0.942\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.978\n  Robust Tucker-Lewis Index (TLI)                            0.971\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.014       0.060\n  90 Percent confidence interval - lower         0.000       0.035\n  90 Percent confidence interval - upper         0.042       0.084\n  P-value RMSEA <= 0.05                          0.989       0.236\n                                                                  \n  Robust RMSEA                                               0.042\n  90 Percent confidence interval - lower                     0.030\n  90 Percent confidence interval - upper                     0.055\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.048       0.048\n\n\n\n\nSpatial-object association test (宇宙黑洞) excluded\n\nCorrelated latent factor model:\n\n\n\nCode\nfitted2 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_dft_set, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted2, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 23 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                31.520      64.307\n  Degrees of freedom                                32          32\n  P-value (Chi-square)                           0.491       0.001\n  Scaling correction factor                                  0.490\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1021.283    1021.283\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       0.967\n  Tucker-Lewis Index (TLI)                       1.001       0.953\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.984\n  Robust Tucker-Lewis Index (TLI)                            0.977\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.056\n  90 Percent confidence interval - lower         0.000       0.027\n  90 Percent confidence interval - upper         0.040       0.084\n  P-value RMSEA <= 0.05                          0.990       0.329\n                                                                  \n  Robust RMSEA                                               0.039\n  90 Percent confidence interval - lower                     0.025\n  90 Percent confidence interval - upper                     0.053\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.044       0.044\n\n\n\nBifactor model:\n\n\n\nCode\nfitted2_bifac <- lavaan::cfa(\n  'Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_dft_set, std.lv = TRUE, std.ov = TRUE, orthogonal = TRUE, \n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted2_bifac, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,\n  bifactor = \"Common\"\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2_bifac, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 47 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                21.313      50.297\n  Degrees of freedom                                25          25\n  P-value (Chi-square)                           0.675       0.002\n  Scaling correction factor                                  0.424\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1021.283    1021.283\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       0.974\n  Tucker-Lewis Index (TLI)                       1.007       0.953\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.989\n  Robust Tucker-Lewis Index (TLI)                            0.980\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.056\n  90 Percent confidence interval - lower         0.000       0.019\n  90 Percent confidence interval - upper         0.036       0.091\n  P-value RMSEA <= 0.05                          0.994       0.343\n                                                                  \n  Robust RMSEA                                               0.037\n  90 Percent confidence interval - lower                     0.022\n  90 Percent confidence interval - upper                     0.051\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.036       0.036\n\n\n\n\n\nTask Structure Model\n\nThe covariance estimate for latent variables is not correct. The estimated correlation between “Simple” and “Complex” is 1.02.\n\n\n\nCode\nfitted3 <- lavaan::cfa(\n  'Complex =~ `打靶场` + `蝴蝶照相机` + `幸运小球`\n  Nback =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  Simple =~ `密码箱` + `顺背数PRO` + `位置记忆PRO`',\n  indices_dft_set, std.lv = TRUE, std.ov = TRUE, \n  estimator = \"WLSM\"\n)\n\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\n\nCode\nsemPlot::semPaths(\n  fitted3, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted3, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 24 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                80.074     161.942\n  Degrees of freedom                                32          32\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.494\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1021.283    1021.283\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.951       0.867\n  Tucker-Lewis Index (TLI)                       0.931       0.813\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.934\n  Robust Tucker-Lewis Index (TLI)                            0.907\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.068       0.112\n  90 Percent confidence interval - lower         0.050       0.089\n  90 Percent confidence interval - upper         0.087       0.138\n  P-value RMSEA <= 0.05                          0.052       0.000\n                                                                  \n  Robust RMSEA                                               0.079\n  90 Percent confidence interval - lower                     0.067\n  90 Percent confidence interval - upper                     0.091\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.071       0.071\n\n\n\n\nInput Material Model\n\nNot fitted well.\n\n\n\nCode\nfitted4 <- lavaan::cfa(\n  'Verbal =~ 数字卡片 + 文字卡片 + 幸运小球 + 密码箱 + 顺背数PRO\n  Spatial =~ 格子卡片 + 打靶场 + 蝴蝶照相机 + 位置记忆PRO\n  Object =~ 美术卡片 + 宇宙黑洞',\n  indices_dft_set, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted4, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted4, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 25 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           314         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               149.509     293.742\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.509\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1109.363    1109.363\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.897       0.760\n  Tucker-Lewis Index (TLI)                       0.862       0.678\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.878\n  Robust Tucker-Lewis Index (TLI)                            0.836\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.092       0.140\n  90 Percent confidence interval - lower         0.076       0.120\n  90 Percent confidence interval - upper         0.108       0.162\n  P-value RMSEA <= 0.05                          0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.100\n  90 Percent confidence interval - lower                     0.090\n  90 Percent confidence interval - upper                     0.111\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.091       0.091"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#correlation-matrix-1",
    "href": "posts/explore-struct-wm/index.html#correlation-matrix-1",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Correlation Matrix",
    "text": "Correlation Matrix\n\n\nCode\nindices_nback_mixed <- indices_memory |> \n  filter(index_name == \"mean_span_pcu\" |\n           (game_name %in% c(\"美术卡片\", \"格子卡片\") & index_name == \"dprime\") |\n           (game_name %in% c(\"文字卡片\", \"数字卡片\") & index_name == \"pc\")) |> \n  pivot_wider_indices() |>\n  select(-user_id)\ncorrelate(indices_nback_mixed, quiet = TRUE) |> \n  rearrange(method = \"HC\") |>\n  stretch() |> \n  mutate(across(c(x, y), as_factor)) |>\n  ggplot(aes(x, y)) +\n  geom_tile(aes(fill = r)) +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"\", y = \"\", fill = \"Pearson's\", color = \"\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#multidimensional-scaling-1",
    "href": "posts/explore-struct-wm/index.html#multidimensional-scaling-1",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Multidimensional Scaling",
    "text": "Multidimensional Scaling\n\n\nCode\nmds <- indices_nback_mixed |> \n  cor(use = \"pairwise\") |> \n  smacof::sim2diss(to.dist = TRUE) |> \n  smacof::mds(ndim = 2, type = \"mspline\")\n# plot(mds, plot.type = \"Shepard\", main = \"Shepard Diagram (Ratio Transformation)\")\n# par(family = \"SimHei\")\nplot(mds)"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#exploratory-factor-analysis-1",
    "href": "posts/explore-struct-wm/index.html#exploratory-factor-analysis-1",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Exploratory Factor Analysis",
    "text": "Exploratory Factor Analysis\n\nTraditional\n\n\nCode\nnfactors_test <- psych::nfactors(indices_nback_mixed)\n\n\n\n\n\n\nCorrelated latent factors\n\n\n\nCode\nfit <- psych::fa(indices_nback_mixed, 3)\npsych::fa.diagram(fit)\n\n\n\n\n\n\nBifactor model\n\n\n\nCode\nfit_bifac <- psych::omega(indices_nback_mixed, 3, plot = FALSE)\npsych::omega.diagram(fit_bifac)\n\n\n\n\n\n\n\nBayesian Factor Analysis\n\n\nCode\nmcmc <- indices_nback_mixed |> \n  mutate(across(.fns = ~ scale(.)[, 1])) |> \n  befa(verbose = FALSE) |> \n  post.column.switch() |> \n  post.sign.switch()\n\n\n\n\nCode\nhppm <- summary(mcmc, what = \"hppm\")\nhppm |> \n  pluck(\"alpha\", \"m1\") |> \n  as_tibble(rownames = \"alpha_term\") |> \n  separate(alpha_term, c(NA, \"game_index\"), sep = \":\") |> \n  mutate(game_index = reorder(game_index, dedic)) |> \n  ggplot(aes(game_index, dedic)) +\n  geom_tile(aes(fill = mean)) +\n  geom_text(aes(label = round(mean, 2)), color = \"white\") +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"Term\", y = \"Factor\", \n       title = str_c(\"Posterior Probability: \", round(hppm$hppm$prob, 2), \n                     \", with \", hppm$hppm$nfac, \" factors\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#confirmatory-factor-analysis-1",
    "href": "posts/explore-struct-wm/index.html#confirmatory-factor-analysis-1",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Confirmatory Factor Analysis",
    "text": "Confirmatory Factor Analysis\n\nModel from EFA\nFirstly, the model from EFA is tested.\n\nSpatial-object association test (宇宙黑洞) included\n\nCorrelated latent factor model:\n\n\n\nCode\nfitted1 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_mixed, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted1, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 24 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           318         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                42.146      86.990\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.421       0.000\n  Scaling correction factor                                  0.484\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1212.943    1212.943\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.999       0.960\n  Tucker-Lewis Index (TLI)                       0.999       0.947\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.981\n  Robust Tucker-Lewis Index (TLI)                            0.974\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.009       0.059\n  90 Percent confidence interval - lower         0.000       0.034\n  90 Percent confidence interval - upper         0.040       0.084\n  P-value RMSEA <= 0.05                          0.993       0.243\n                                                                  \n  Robust RMSEA                                               0.041\n  90 Percent confidence interval - lower                     0.029\n  90 Percent confidence interval - upper                     0.053\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.047       0.047\n\n\n\nBifactor model:\n\n\n\nCode\nfitted1_bifac <- lavaan::cfa(\n  'Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_mixed, std.lv = TRUE, std.ov = TRUE, orthogonal = TRUE, \n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted1_bifac, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,\n  bifactor = \"Common\"\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 24 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           318         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                42.146      86.990\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.421       0.000\n  Scaling correction factor                                  0.484\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1212.943    1212.943\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.999       0.960\n  Tucker-Lewis Index (TLI)                       0.999       0.947\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.981\n  Robust Tucker-Lewis Index (TLI)                            0.974\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.009       0.059\n  90 Percent confidence interval - lower         0.000       0.034\n  90 Percent confidence interval - upper         0.040       0.084\n  P-value RMSEA <= 0.05                          0.993       0.243\n                                                                  \n  Robust RMSEA                                               0.041\n  90 Percent confidence interval - lower                     0.029\n  90 Percent confidence interval - upper                     0.053\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.047       0.047\n\n\n\n\nSpatial-object association test (宇宙黑洞) excluded\n\nCorrelated latent factor model:\n\n\n\nCode\nfitted2 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_mixed, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted2, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 25 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           326         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                30.066      63.597\n  Degrees of freedom                                32          32\n  P-value (Chi-square)                           0.565       0.001\n  Scaling correction factor                                  0.473\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1104.555    1104.555\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       0.970\n  Tucker-Lewis Index (TLI)                       1.003       0.958\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.986\n  Robust Tucker-Lewis Index (TLI)                            0.980\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.055\n  90 Percent confidence interval - lower         0.000       0.025\n  90 Percent confidence interval - upper         0.038       0.084\n  P-value RMSEA <= 0.05                          0.994       0.350\n                                                                  \n  Robust RMSEA                                               0.038\n  90 Percent confidence interval - lower                     0.024\n  90 Percent confidence interval - upper                     0.051\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.043       0.043\n\n\n\nBifactor model:\n\n\n\nCode\nfitted2_bifac <- lavaan::cfa(\n  'Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_mixed, std.lv = TRUE, std.ov = TRUE, orthogonal = TRUE, \n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted2_bifac, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,\n  bifactor = \"Common\"\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2_bifac, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 46 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n                                                      \n                                                  Used       Total\n  Number of observations                           326         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                22.343      55.450\n  Degrees of freedom                                25          25\n  P-value (Chi-square)                           0.616       0.000\n  Scaling correction factor                                  0.403\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1104.555    1104.555\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       0.971\n  Tucker-Lewis Index (TLI)                       1.005       0.948\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.988\n  Robust Tucker-Lewis Index (TLI)                            0.979\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.061\n  90 Percent confidence interval - lower         0.000       0.026\n  90 Percent confidence interval - upper         0.039       0.096\n  P-value RMSEA <= 0.05                          0.991       0.260\n                                                                  \n  Robust RMSEA                                               0.039\n  90 Percent confidence interval - lower                     0.025\n  90 Percent confidence interval - upper                     0.053\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.038       0.038\n\n\n\n\n\nTask Structure Model\n\nThe covariance estimate for latent variables is not correct. The estimated correlation between “Simple” and “Complex” is 1.05.\n\n\n\nCode\nfitted3 <- lavaan::cfa(\n  'Complex =~ `打靶场` + `蝴蝶照相机` + `幸运小球`\n  Nback =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  Simple =~ `密码箱` + `顺背数PRO` + `位置记忆PRO`',\n  indices_nback_mixed, std.lv = TRUE, std.ov = TRUE, \n  estimator = \"WLSM\"\n)\n\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\n\nCode\nsemPlot::semPaths(\n  fitted3, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted3, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 24 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           326         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                75.898     157.953\n  Degrees of freedom                                32          32\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.481\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1104.555    1104.555\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.959       0.881\n  Tucker-Lewis Index (TLI)                       0.942       0.833\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.943\n  Robust Tucker-Lewis Index (TLI)                            0.920\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065       0.110\n  90 Percent confidence interval - lower         0.046       0.086\n  90 Percent confidence interval - upper         0.084       0.135\n  P-value RMSEA <= 0.05                          0.091       0.000\n                                                                  \n  Robust RMSEA                                               0.076\n  90 Percent confidence interval - lower                     0.065\n  90 Percent confidence interval - upper                     0.088\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.069       0.069\n\n\n\n\nInput Material Model\n\nNot fitted well.\n\n\n\nCode\nfitted4 <- lavaan::cfa(\n  'Verbal =~ 数字卡片 + 文字卡片 + 幸运小球 + 密码箱 + 顺背数PRO\n  Spatial =~ 格子卡片 + 打靶场 + 蝴蝶照相机 + 位置记忆PRO\n  Object =~ 美术卡片 + 宇宙黑洞',\n  indices_nback_mixed, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted4, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted4, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 25 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           318         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               149.478     302.290\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.494\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1212.943    1212.943\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.906       0.774\n  Tucker-Lewis Index (TLI)                       0.874       0.697\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.888\n  Robust Tucker-Lewis Index (TLI)                            0.850\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.091       0.142\n  90 Percent confidence interval - lower         0.076       0.121\n  90 Percent confidence interval - upper         0.107       0.164\n  P-value RMSEA <= 0.05                          0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.100\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.110\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.090       0.090"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#correlation-matrix-2",
    "href": "posts/explore-struct-wm/index.html#correlation-matrix-2",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Correlation Matrix",
    "text": "Correlation Matrix\n\n\nCode\nindices_nback_pc <- indices_memory |> \n  filter(index_name %in% c(\"mean_span_pcu\", \"pc\")) |> \n  pivot_wider_indices() |>\n  select(-user_id)\ncorrelate(indices_nback_pc, quiet = TRUE) |> \n  rearrange(method = \"HC\") |>\n  stretch() |> \n  mutate(across(c(x, y), as_factor)) |>\n  ggplot(aes(x, y)) +\n  geom_tile(aes(fill = r)) +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"\", y = \"\", fill = \"Pearson's\", color = \"\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#multidimensional-scaling-2",
    "href": "posts/explore-struct-wm/index.html#multidimensional-scaling-2",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Multidimensional Scaling",
    "text": "Multidimensional Scaling\n\n\nCode\nmds <- indices_nback_pc |> \n  cor(use = \"pairwise\") |> \n  smacof::sim2diss(to.dist = TRUE) |> \n  smacof::mds(ndim = 2, type = \"mspline\")\n# plot(mds, plot.type = \"Shepard\", main = \"Shepard Diagram (Ratio Transformation)\")\n# par(family = \"SimHei\")\nplot(mds)"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#exploratory-factor-analysis-2",
    "href": "posts/explore-struct-wm/index.html#exploratory-factor-analysis-2",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Exploratory Factor Analysis",
    "text": "Exploratory Factor Analysis\n\nTraditional\n\n\nCode\nnfactors_test <- psych::nfactors(indices_nback_pc)\n\n\n\n\n\n\nCorrelated latent factors\n\n\n\nCode\nfit <- psych::fa(indices_nback_pc, 3)\npsych::fa.diagram(fit)\n\n\n\n\n\n\nBifactor model\n\n\n\nCode\nfit_bifac <- psych::omega(indices_nback_pc, 3, plot = FALSE)\npsych::omega.diagram(fit_bifac)\n\n\n\n\n\n\n\nBayesian Factor Analysis\n\n\nCode\nmcmc <- indices_nback_pc |> \n  mutate(across(.fns = ~ scale(.)[, 1])) |> \n  befa(verbose = FALSE) |> \n  post.column.switch() |> \n  post.sign.switch()\n\n\n\n\nCode\nhppm <- summary(mcmc, what = \"hppm\")\nhppm |> \n  pluck(\"alpha\", \"m1\") |> \n  as_tibble(rownames = \"alpha_term\") |> \n  separate(alpha_term, c(NA, \"game_index\"), sep = \":\") |> \n  mutate(game_index = reorder(game_index, dedic)) |> \n  ggplot(aes(game_index, dedic)) +\n  geom_tile(aes(fill = mean)) +\n  geom_text(aes(label = round(mean, 2)), color = \"white\") +\n  scico::scale_fill_scico(palette = \"bam\", midpoint = 0, direction = -1) +\n  coord_fixed() +\n  theme_minimal(base_size = 18) +\n  labs(x = \"Term\", y = \"Factor\", \n       title = str_c(\"Posterior Probability: \", round(hppm$hppm$prob, 2), \n                     \", with \", hppm$hppm$nfac, \" factors\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/explore-struct-wm/index.html#confirmatory-factor-analysis-2",
    "href": "posts/explore-struct-wm/index.html#confirmatory-factor-analysis-2",
    "title": "Explore Cognitive Structure for Working Memory",
    "section": "Confirmatory Factor Analysis",
    "text": "Confirmatory Factor Analysis\n\nModel from EFA\nFirstly, the model from EFA is tested.\n\nSpatial-object association test (宇宙黑洞) included\n\nCorrelated latent factor model:\n\n\n\nCode\nfitted1 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_pc, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted1, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 23 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                45.186      93.942\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.301       0.000\n  Scaling correction factor                                  0.481\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1285.695    1285.695\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.957\n  Tucker-Lewis Index (TLI)                       0.995       0.942\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.979\n  Robust Tucker-Lewis Index (TLI)                            0.972\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.018       0.063\n  90 Percent confidence interval - lower         0.000       0.039\n  90 Percent confidence interval - upper         0.043       0.088\n  P-value RMSEA <= 0.05                          0.986       0.167\n                                                                  \n  Robust RMSEA                                               0.044\n  90 Percent confidence interval - lower                     0.032\n  90 Percent confidence interval - upper                     0.056\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.049       0.049\n\n\n\nBifactor model:\n\n\n\nCode\nfitted1_bifac <- lavaan::cfa(\n  'Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_pc, std.lv = TRUE, std.ov = TRUE, orthogonal = TRUE, \n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted1_bifac, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,\n  bifactor = \"Common\"\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted1, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 23 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                45.186      93.942\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.301       0.000\n  Scaling correction factor                                  0.481\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1285.695    1285.695\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.957\n  Tucker-Lewis Index (TLI)                       0.995       0.942\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.979\n  Robust Tucker-Lewis Index (TLI)                            0.972\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.018       0.063\n  90 Percent confidence interval - lower         0.000       0.039\n  90 Percent confidence interval - upper         0.043       0.088\n  P-value RMSEA <= 0.05                          0.986       0.167\n                                                                  \n  Robust RMSEA                                               0.044\n  90 Percent confidence interval - lower                     0.032\n  90 Percent confidence interval - upper                     0.056\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.049       0.049\n\n\n\n\nSpatial-object association test (宇宙黑洞) excluded\n\nCorrelated latent factor model:\n\n\n\nCode\nfitted2 <- lavaan::cfa(\n  'Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_pc, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted2, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 25 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           330         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                30.388      63.503\n  Degrees of freedom                                32          32\n  P-value (Chi-square)                           0.548       0.001\n  Scaling correction factor                                  0.479\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1135.471    1135.471\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       0.971\n  Tucker-Lewis Index (TLI)                       1.002       0.959\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.986\n  Robust Tucker-Lewis Index (TLI)                            0.981\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.055\n  90 Percent confidence interval - lower         0.000       0.025\n  90 Percent confidence interval - upper         0.038       0.083\n  P-value RMSEA <= 0.05                          0.994       0.358\n                                                                  \n  Robust RMSEA                                               0.038\n  90 Percent confidence interval - lower                     0.024\n  90 Percent confidence interval - upper                     0.051\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.043       0.043\n\n\n\nBifactor model:\n\n\n\nCode\nfitted2_bifac <- lavaan::cfa(\n  'Common =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片` + `幸运小球` + `密码箱` + `顺背数PRO` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`\n  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`\n  SpatialSTM =~ `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',\n  indices_nback_pc, std.lv = TRUE, std.ov = TRUE, orthogonal = TRUE, \n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted2_bifac, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, \n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,\n  bifactor = \"Common\"\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted2_bifac, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 45 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n                                                      \n                                                  Used       Total\n  Number of observations                           330         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                23.937      59.081\n  Degrees of freedom                                25          25\n  P-value (Chi-square)                           0.523       0.000\n  Scaling correction factor                                  0.405\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1135.471    1135.471\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       0.969\n  Tucker-Lewis Index (TLI)                       1.002       0.944\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.987\n  Robust Tucker-Lewis Index (TLI)                            0.977\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.064\n  90 Percent confidence interval - lower         0.000       0.031\n  90 Percent confidence interval - upper         0.042       0.098\n  P-value RMSEA <= 0.05                          0.985       0.210\n                                                                  \n  Robust RMSEA                                               0.041\n  90 Percent confidence interval - lower                     0.028\n  90 Percent confidence interval - upper                     0.055\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.039       0.039\n\n\n\n\n\nTask Structure Model\n\nThe covariance estimate for latent variables is not correct. The estimated correlation between “Simple” and “Complex” is 1.05.\n\n\n\nCode\nfitted3 <- lavaan::cfa(\n  'Complex =~ `打靶场` + `蝴蝶照相机` + `幸运小球`\n  Nback =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`\n  # AscMem =~ `人工语言-中级` + `欢乐餐厅` + 图片记忆\n  Simple =~ `密码箱` + `顺背数PRO` + `位置记忆PRO`',\n  indices_nback_pc, std.lv = TRUE, std.ov = TRUE, \n  estimator = \"WLSM\"\n)\n\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\n\nCode\nsemPlot::semPaths(\n  fitted3, what = \"std\", edge.color = \"black\", layout = \"tree2\",\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted3, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 25 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n                                                      \n                                                  Used       Total\n  Number of observations                           330         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                72.669     147.808\n  Degrees of freedom                                32          32\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.492\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1135.471    1135.471\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.963       0.894\n  Tucker-Lewis Index (TLI)                       0.948       0.851\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.948\n  Robust Tucker-Lewis Index (TLI)                            0.927\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.062       0.105\n  90 Percent confidence interval - lower         0.043       0.081\n  90 Percent confidence interval - upper         0.081       0.130\n  P-value RMSEA <= 0.05                          0.137       0.000\n                                                                  \n  Robust RMSEA                                               0.074\n  90 Percent confidence interval - lower                     0.062\n  90 Percent confidence interval - upper                     0.086\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.067       0.067\n\n\n\n\nInput Material Model\n\nNot fitted well.\n\n\n\nCode\nfitted4 <- lavaan::cfa(\n  'Verbal =~ 数字卡片 + 文字卡片 + 幸运小球 + 密码箱 + 顺背数PRO\n  Spatial =~ 格子卡片 + 打靶场 + 蝴蝶照相机 + 位置记忆PRO\n  Object =~ 美术卡片 + 宇宙黑洞',\n  indices_nback_pc, std.lv = TRUE, std.ov = TRUE,\n  estimator = \"WLSM\"\n)\nsemPlot::semPaths(\n  fitted4, what = \"std\", edge.color = \"black\", rotation = 2,\n  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6,\n  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0\n)\n\n\n\n\n\nCode\nlavaan::summary(fitted4, fit.measures = TRUE, estimates = FALSE)\n\n\nlavaan 0.6-11 ended normally after 25 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n                                                      \n                                                  Used       Total\n  Number of observations                           322         468\n                                                                  \nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               151.497     305.170\n  Degrees of freedom                                41          41\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.496\n       Satorra-Bentler correction                                 \n\nModel Test Baseline Model:\n\n  Test statistic                              1285.695    1285.695\n  Degrees of freedom                                55          55\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.910       0.785\n  Tucker-Lewis Index (TLI)                       0.880       0.712\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.893\n  Robust Tucker-Lewis Index (TLI)                            0.857\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.092       0.142\n  90 Percent confidence interval - lower         0.076       0.121\n  90 Percent confidence interval - upper         0.107       0.163\n  P-value RMSEA <= 0.05                          0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.100\n  90 Percent confidence interval - lower                     0.090\n  90 Percent confidence interval - upper                     0.110\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.090       0.090"
  }
]